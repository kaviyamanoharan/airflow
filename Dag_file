from datetime import timedelta
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from airflow.operators.dummy_operator import DummyOperator
from datetime import timedelta, datetime
from airflow.operators.email_operator import EmailOperator
import imp
default_args = {
        'owner':'kaviyamano',
        'start_date':datetime(2023, 5, 7),
        'retries':3,
        'retry_delay': timedelta(minutes=5)
        }
dag = DAG('Timberland_stock',
        default_args = default_args,
        description='Timberland DAG',
        schedule_interval='* * * * *',
        catchup = False,
        )


task1 =DummyOperator(task_id='task1', dag=dag)
def spark_submit_job():
    my_module = imp.load_source('my_module', '/home/kaviyamanoharan/airflow/sparkjobs/timber_analysis.py')

task2 = PythonOperator(
    task_id='task2',
    python_callable=spark_submit_job,
    dag=dag
)
task3 = DummyOperator(task_id='task3', dag=dag)
task4 = EmailOperator(
        task_id = "task4",
        to=['kaviyamano.1.4@gmail.com'],
        subject = "Airflow Alert!",
        html_content="<i>Msg from Airflow -- outputfile is generated</i>",
        cc=['kavinal@gmail.com'],
        dag=dag
        )
task1 >> task2 >> task3 >> task4
